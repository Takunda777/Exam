{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "# Extended Learning Portfolio\n",
        "\n",
        "**ISYS2001 Introduction to Business Programming**\n",
        "\n",
        "<small>School of Management\n",
        "\n",
        "Semester 1 2023\n",
        "</small>\n",
        "</center>\n",
        "\n",
        "This examination is an open-book format. You are permitted to utilise a variety of resources, including textbooks, web content, and AI tools, to complete the exam. However, it's important to note that all work submitted must be your own. Any work or ideas not your own must be properly referenced. \n",
        "\n",
        "Please refrain from discussing your responses to these questions with fellow students. If you have any inquiries about the questions about this assessment, please contact the instructor directly.  Any questions submitted to the instructor concerning this assesment will have the question and responses will be posted to this discussion forum.  \n",
        "\n",
        "The examination duration is a total of 24 hours. This time frame begins at the predetermined exam start time and does not depend on when you commence the download. If you have accommodations under a CAP arrangement, the duration of the exam will be adjusted accordingly. If you feel that your CAP accommodations have not been satisfactorily implemented, please reach out to me immediately.\n",
        "\n",
        "This examination consists of four questions in total, and you are required to provide answers to all of them. Each question should be contained within its own notebook, with the exception of Question Four, which can be compiled in a Microsoft Word document. To submit your answers, please establish a private GitHub repository and upload all of your responses to the designated questions, inclusive of the Word document for Question Four, to this repository.\n",
        "\n",
        "Upon completion of all the questions, proceed to download the zip file of your GitHub repository. This file should be submitted via the link provided on Blackboard. Additionally, a separate submission of the Word document for Question Four must be made through the Turnitin link available on Blackboard."
      ],
      "metadata": {
        "id": "1M9yB5U0yefZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1\n",
        "\n",
        "Write a Python program within this or another notebook that performs advanced file analysis. The program should prompt the user to enter the path to a text file and allow them to choose from various analysis options:\n",
        "\n",
        "* Counting the number of lines.\n",
        "* Counting the total number of words.\n",
        "* Counting the total number of characters, both including and excluding whitespace.\n",
        "* Identifying the frequency of each word in the text.\n",
        "* Identifying the top 5 most common words in the text.\n",
        "\n",
        "After receiving the user input, your program should read the file and perform the chosen analysis, outputting the results in a clear, human-readable format.\n",
        "\n",
        "*Question subparts:*\n",
        "\n",
        "1. Implement the notebook program as described above. Your program should be robust and handle possible edge cases, such as file not found or incorrect input from the user.\n",
        "2. Write a brief description of your program, explaining how to use it and what each analysis option does. This description should be written as if for other developers or users who might use your tool.\n",
        "3. Write a few test cases to validate your tool. Consider edge cases such as empty files, very large files, files with unusual characters, and so on.\n",
        "4. Discuss how you would modify your tool to analyze binary files, or large files that do not fit into memory. What kind of analysis could be useful in these cases?\n",
        "5. Provide a few example text files and show the output of your program when run with these files.\n",
        "\n",
        "Remember to include necessary error handling in your program to make it robust and reliable.\n",
        "\n",
        "**[40 Marks]**"
      ],
      "metadata": {
        "id": "w3Y-At852J91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Explaination**\n",
        "\n",
        "2.) This program pretty much asks the user to enter the path from the readme file in order for it to activate the next step.\n",
        "\n",
        "After the user does that it then prompts the user to choose one of the five options that ere displayed and then gives the answer.\n",
        "\n",
        "3.) I then created an empty file, large file and found an incorrect path on my laptop, ran the program and provided the path for the empty file, Large File and an incorrect path, chose analysis option 3 and the output was still the same.\n",
        "\n",
        "4.) Large files that dont fit into memory can be abit of a problem as reading the whole file in one go might not be possible. So instead of reading the while file into memory it can get processed in chuncks.\n",
        "\n",
        "Various analysis options can be created to work with streamed data, to allow incremental processing. Analysis options such as counting lines in chunks identifying frequency of specific patterns or keywords without storing the whole file in memory.\n"
      ],
      "metadata": {
        "id": "WnkxOCH7RN-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6DXwieOyV39"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "#Counts number of lines in the file itsfelf.\n",
        "#Args:file_path (str): Path to the text files location.\n",
        "#Returns: int: The number  of lines in file.\n",
        "def count_lines(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        line_count = sum(1 for _ in file)\n",
        "    return line_count\n",
        "\n",
        "#Counts number of characters in file\n",
        "#Counts the total number of characters in given file, including or even excluding the whitespace.Args:file_path (str): Path to text file.include_whitespace (bool, optional): Whether to include the whitespace in character count. Defaults to True.\n",
        "#Returns:int: The Number of characters in file.\n",
        "\n",
        "def count_characters(file_path, include_whitespace=True):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        if include_whitespace:\n",
        "            char_count = len(content)\n",
        "        else:\n",
        "            content = content.replace(\" \", \"\")\n",
        "            char_count = len(content)\n",
        "    return char_count\n",
        "\n",
        "#Counts number of words in the file itself.\n",
        "#Args:file_path (str): Path to the text files location.\n",
        "#Returns:int: The Number of words in file.\n",
        "\n",
        "def count_words(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        word_count = 0\n",
        "        for line in file:\n",
        "            words = line.split()\n",
        "            word_count += len(words)\n",
        "    return word_count\n",
        "\n",
        "#Identifies the top N most common words in the file\n",
        "\n",
        "def top_common_words(file_path, num_words=5):\n",
        "    word_count = word_frequency(file_path)\n",
        "    common_words = word_count.most_common(num_words)\n",
        "    return common_words\n",
        "\n",
        "#Identifies the word frequency in each of the files\n",
        "\n",
        "def word_frequency(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        content = content.translate(str.maketrans('', '', string.punctuation))\n",
        "        words = content.lower().split()\n",
        "        word_count = Counter(words)\n",
        "    return word_count\n",
        "\n",
        "#Analyzes the file depending on the users input\n",
        "\n",
        "def analyze_file(file_path):\n",
        "    print(f\"Analyzing file: {file_path}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"1. Count the number of lines\")\n",
        "    print(\"2. Count the total number of words\")\n",
        "    print(\"3. Count the total number of characters (including whitespace)\")\n",
        "    print(\"4. Count the total number of characters (excluding whitespace)\")\n",
        "    print(\"5. Identify the frequency of each word in the text\")\n",
        "    print(\"6. Identify the top 5 most common words in the text\")\n",
        "    print(\"-\" * 40)\n",
        "    choice = input(\"Enter your choice (1-6): \")\n",
        "\n",
        "    if choice == '1':\n",
        "        line_count = count_lines(file_path)\n",
        "        print(f\"Number of lines: {line_count}\")\n",
        "    elif choice == '2':\n",
        "        word_count = count_words(file_path)\n",
        "        print(f\"Number of words: {word_count}\")\n",
        "    elif choice == '3':\n",
        "        char_count = count_characters(file_path)\n",
        "        print(f\"Number of characters (including whitespace): {char_count}\")\n",
        "    elif choice == '4':\n",
        "        char_count = count_characters(file_path, include_whitespace=False)\n",
        "        print(f\"Number of characters (excluding whitespace): {char_count}\")\n",
        "    elif choice == '5':\n",
        "        word_count = word_frequency(file_path)\n",
        "        print(\"Word frequency:\")\n",
        "        for word, count in word_count.items():\n",
        "            print(f\"{word}: {count}\")\n",
        "    elif choice == '6':\n",
        "        common_words = top_common_words(file_path)\n",
        "        print(\"Top 5 most common words:\")\n",
        "        for word, count in common_words:\n",
        "            print(f\"{word}: {count}\")\n",
        "    else:\n",
        "        print(\"Invalid choice!\")\n",
        "\n",
        "file_path = input(\"Enter the path to the text file: \")\n",
        "analyze_file(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2\n",
        "\n",
        "**Question:**\n",
        "\n",
        "As a new junior developer at EcommEasy, an e-commerce platform company, you're assigned to debug and refactor a piece of code left by one of the departed team members. This code is meant to determine if a customer is eligible for a certain promotional discount based on their total order value.\n",
        "\n",
        "Unfortunately, the code is obfuscated, lacks documentation, and doesn't function as expected. Your task is to identify the error, correct it, and refactor the code according to the best industry practices, which include clear variable naming, detailed comments, error handling, and overall code readability. \n",
        "\n",
        "Here is the problematic code:\n",
        "\n",
        "```python\n",
        "def promo(o):\n",
        "    p = None\n",
        "    if o > 50 and o < 100:\n",
        "        p = 5\n",
        "    elif o > 100:\n",
        "        p = 10\n",
        "    else:\n",
        "        p = 0\n",
        "    if o <= 0 or o is None:\n",
        "        raise ValueError(\"Order value not valid!\")\n",
        "    return o*(p/100)\n",
        "```\n",
        "\n",
        "*Question subparts:*\n",
        "\n",
        "1. What is the error in the above code and why does it fail to calculate the promotional discount correctly?\n",
        "2. How would you correct the error?\n",
        "3. How would you refactor this code to align it with industry best practices? Write the refactored code within this or another notebook. Please include appropriate variable names, comments, error handling, and a basic explanation of the code for a layperson.\n",
        "4. Write a few test cases to confirm the code is functioning as expected.\n",
        "\n",
        "Hint: The promo function is supposed to apply a 5% discount if the order total is between \\$50 and \\$100 (inclusive), and a 10% discount if the order total exceeds \\$100. Orders less than or equal to \\$0 or null should raise an exception.\n",
        "\n",
        "**[20 Marks]**"
      ],
      "metadata": {
        "id": "yYD1q2Mx95vB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Explaination**\n",
        "\n",
        "1.) The error in this above code is in the arrangement of the conditional statements. The code is only checking the first condition and assigning a promotional value of 5%.\n",
        "\n",
        "2.) I would correct this error by rearanging the conditional statements so they can check the higher value first.\n",
        "\n",
        "3.) I've written clean and readable code, Ive added error handling in order to order to align this code with best industry practices and Ive wirtten moduler code. \n",
        "\n",
        "This code is written in Python and defines a function called promo. This function takes in a parameter called \"o\", which represents the order value. This function first initializes a variable called \"p\" to 0.\n",
        "\n",
        "This then checks if the order value is None or less than or equal to 0. If it is then the function raises an ValueError. If the order value is greater than 50 and less than 100, it then sets the \"p\" variable to 5. If the order value is greater than 100, it will set the \"p\" variable to 10.\n",
        "\n",
        "Lastly, the function returns the order value multiplied by p/100 to calculate the discount for the order.\n",
        "\n",
        "4.) Test cases are written below the code"
      ],
      "metadata": {
        "id": "OqWwAeCX9-K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_order_discount(order_value):\n",
        "  # Initialize the discount_percent to 0\n",
        "    discount_percent = 0\n",
        "  # Check if order_value is within the range (50, 100)\n",
        "    if order_value > 50 and order_value < 100:\n",
        "        discount_percent = 5\n",
        "  # Check if the order_value is greater than 100\n",
        "    elif order_value > 100:\n",
        "        discount_percent = 10\n",
        "    else:\n",
        "  # If order_value is less than or equal to 50, no discount is to be applied\n",
        "        discount_percent = 0\n",
        "  # Check if the order_value is invalid (less than or equal to 0 or None)\n",
        "    if order_value <= 0 or order_value is None:\n",
        "        raise ValueError(\"Order value not valid!\")\n",
        "  # Calculate the discount amount and return it\n",
        "    return order_value * (discount_percent / 100)\n",
        "\n",
        "  # This is the test case \n",
        "def calculate_order_discount(order_value):\n",
        "    discount_percent = 0\n",
        "    if order_value > 50 and order_value < 100:\n",
        "        discount_percent = 5\n",
        "    elif order_value > 100:\n",
        "        discount_percent = 10\n",
        "    else:\n",
        "        discount_percent = 0\n",
        "\n",
        "    if order_value <= 0 or order_value is None:\n",
        "        raise ValueError(\"Order value not valid!\")\n",
        "\n",
        "    return order_value * (discount_percent / 100)\n",
        "\n",
        "if __name__== '_main_':\n",
        "\n",
        "    assert calculate_order_discount(40) == 0\n",
        "    assert calculate_order_discount(75) == 3.75\n",
        "    assert calculate_order_discount(200) == 20\n",
        "    \n",
        "    # add inline unit tests\n",
        "    assert calculate_order_discount(30) == 0\n",
        "    assert calculate_order_discount(110) == 11.0\n",
        "    assert calculate_order_discount(65) == 3.25\n",
        "    assert calculate_order_discount(150) == 15.0\n",
        "    \n",
        "try:\n",
        "    # Test raised value error messages\n",
        "    calculate_order_discount(0)\n",
        "except ValueError as error:\n",
        "    assert str(error) == \"Order value not valid!\"\n",
        "        \n",
        "try:\n",
        "    # Test raised value error messages\n",
        "    calculate_order_discount(-1)\n",
        "except ValueError as error:\n",
        "    assert str(error) == \"Order value not valid!\"\n"
      ],
      "metadata": {
        "id": "IWWm6XAjfI3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3\n",
        "\n",
        "You have been given a task to develop a simple script that extracts news articles' title and text from a list of URLs. Your company, DataScrapr, is working on a project to analyze the sentiment of news articles from several news outlets and this task is the first step in the data collection process.\n",
        "\n",
        "The task requires you to use Python, along with the `Newspaper3k` library, which is a simple and efficient tool for extracting and curating articles.\n",
        "\n",
        "Here is your task:\n",
        "\n",
        "1. Write a Python script that takes a list of URLs as input. Each URL points to a news article.\n",
        "2. For each URL, your script should extract the article's title and the full text of the article.\n",
        "3. The output of your script should be a list of dictionaries. Each dictionary should contain the URL, the article title, and the article text.\n",
        "4. Include error checking in your script to handle possible issues with the URLs or the extraction process. \n",
        "\n",
        "*Question subparts:*\n",
        "\n",
        "1. Implement the above-described script.\n",
        "2. Explain how your script works and the role of the `Newspaper3k` library in the script.\n",
        "3. How would you handle potential issues, such as a URL that doesn't point to a valid article or network errors?\n",
        "4. Provide a few example URLs and show the output of your script when run with these URLs.\n",
        "\n",
        "Note: Please be mindful of the terms of use for any website you are scraping, and make sure to respect the website's robots.txt file.\n",
        "\n",
        "**[25 marks]**"
      ],
      "metadata": {
        "id": "YaDX0dOQA_py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Explaination**\n",
        "\n",
        "2) This script is using the newspaper library to get content from news stories it retrieves data from a list of URLs. The following actions are taken by the script when it loops through each URL in the list:\n",
        "\n",
        "A creation of a Article object using the supplied URL utilizes the download() function to download the article's website content. uses the parse() method to analyze the downloaded content and extract the article's title and primary text.\n",
        "adds the dictionary to a list of article dictionaries after adding the extracted metadata (title, text, and URL) to it.\n",
        "\n",
        "3) If there are any failures (requests.exceptions), it will then moves on to the next URL.When downloading/processing the current URL failed because of a RequestException or ValueError.\n",
        "The list of article dictionaries is exactly what the function extract_articles() returns right at the end. the article follows. The console receives printed dictionaries.\n",
        "\n",
        "Data from the news articles is downloaded and then scraped when using the newspaper library. It offers an intuitive interface when it comes to extracting metadata such authors, publish dates and article titles, as well as the article text itself. It is built on top of beautifulsoup4, lxml, and requests packages. The library works with articles from a variety of news sources and employs machine learning algorithms to try and determine an article's primary subject matter.  "
      ],
      "metadata": {
        "id": "gQfnMObggph3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Explaination**\n",
        "\n"
      ],
      "metadata": {
        "id": "faZQcmBCfyk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#From newspaper import Article \n",
        "import requests\n",
        "#List of URLs for article extraction\n",
        "example_urls = [\n",
        "   'https://rosettacode.org/wiki/Wireworld',\n",
        "  'https://react.dev/reference/react/useState'\n",
        "]\n",
        "\n",
        "def extract_articles(urls):\n",
        "#List to store extracted articles\n",
        "    articles = []\n",
        "#Iterate through the URLS\n",
        "    for url in urls:\n",
        "        try:\n",
        "#Create an instance of article class\n",
        "            article = Article(url)\n",
        "#Download articel aswell as parse it\n",
        "            article.download()\n",
        "            article.parse()\n",
        "#Create a documentary in roder to store all the article details\n",
        "            article_dict = {}\n",
        "            article_dict[\"url\"] = url\n",
        "            article_dict[\"title\"] = article.title\n",
        "            article_dict[\"text\"] = article.text\n",
        "#Append articles to the list of articles\n",
        "            articles.append(article_dict)\n",
        "        except (requests.exceptions.RequestException, ValueError):\n",
        "            print(f\"Error processing {url}\")\n",
        "            continue\n",
        "#Print the article that were extracted\n",
        "    for article in articles:\n",
        "        print(article)\n",
        "#Call extract articles funtion that has all the sample URLS\n",
        "if __name__ == \"_main_\":\n",
        "    articles = extract_articles(example_urls)"
      ],
      "metadata": {
        "id": "osaBpxsQfIQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4\n",
        "\n",
        "Write a reflective report that identifies and discusses what you perceive as the most impactful activity within this course unit, and its contributions to your understanding of an ISYS2001 activity or topic. **Additionally, please incorporate all your weekly journal entries as an appendix to this report.** The report should be prepared in a Microsoft Word document, which will be submitted via the TurnItin link available on Blackboard.\n",
        "\n",
        "**[15 marks]**"
      ],
      "metadata": {
        "id": "YQ0itNBkCClk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1MRfZlWQCB_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}